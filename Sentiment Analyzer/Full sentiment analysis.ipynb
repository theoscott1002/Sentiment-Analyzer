{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518c3c8-83fd-419f-90e8-07b41033cf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Israel\\AppData\\Local\\Temp\\ipykernel_5536\\401322845.py:153: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Firefox(executable_path=r'C:\\Users\\Israel\\anaconda3\\geckodriver')\n",
      "C:\\Users\\Israel\\AppData\\Local\\Temp\\ipykernel_5536\\401322845.py:158: DeprecationWarning: find_elements_by_xpath is deprecated. Please use find_elements(by=By.XPATH, value=xpath) instead\n",
      "  comment = browser.find_elements_by_xpath('//div[@class=\"narrow\"]')\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import os\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from termcolor import colored\n",
    "import statistics as st\n",
    "import pandas as pd\n",
    "import nltk \n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from nltk import FreqDist\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "import tkinter.font as tkFont\n",
    "matplotlib.use(\"TkAgg\")\n",
    "# Top level window\n",
    "win = Tk()\n",
    "win.title(\"Sentiment Analysis\")\n",
    "win.geometry(\"700x350\")\n",
    "\n",
    "\n",
    "# Function for getting Input\n",
    "# from textbox and printing it \n",
    "# at label widget\n",
    "\n",
    "# @@@@@@@@@@@@@@@@@--------- (Function For Twitter) -------------@@@@@@@@@@@@@@@@@@ #\n",
    "def twitterInput():\n",
    "    tInp = entry.get()\n",
    "    browser = webdriver.Firefox(executable_path=r'C:\\Users\\Israel\\anaconda3\\geckodriver')\n",
    "    browser.get(tInp)\n",
    "#scroll to the end of the page\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(60)\n",
    "    comment = browser.find_elements_by_xpath('//span[@class=\"css-901oao css-16my406 r-poiln3 r-bcqeeo r-qvutc0\"]')\n",
    "    xcomment = []\n",
    "    x=0\n",
    "    for v in range(len(comment)):\n",
    "        xcomment.append(comment[v].text)\n",
    "        x+=1\n",
    "        #print((colored('COMMENT-', 'red', attrs=['bold'])) + str(x)+\" \"+\"is:\"+comment[v].text)\n",
    "    string = ' '.join([str(item) for item in xcomment])\n",
    "    lower_case = string.lower() \n",
    "    result = re.sub(r\"\\d+\", \"\", lower_case)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', result)\n",
    "#Tokenization\n",
    "    tokenized_words = cleaned_text.split()\n",
    "#Removing stopwords\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    final_words =[]\n",
    "    for word in tokenized_words:\n",
    "        if word not in stopwords:\n",
    "            final_words.append(word)\n",
    "        \n",
    "\n",
    "#To clear the lines type\n",
    "    emotion_list = []\n",
    "\n",
    "    with open('emotions.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            clear_line = line.replace(\"\\n\", '').replace(\",\", '').replace(\"'\", '').strip()\n",
    "            words, emotion = clear_line.split(':')\n",
    "            #print(\"Word:\"+words+\"     \"+\"Emotion:\" + emotion)\n",
    "            if words in final_words:\n",
    "                emotion_list.append(emotion)\n",
    "#To count the emotions\n",
    "    w = Counter(emotion_list)\n",
    "    print(w)\n",
    "    figure = Figure(figsize=(3, 3), dpi=100)\n",
    "\n",
    "#PLOTTING THE GRAPHS\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.bar(w.keys(), w.values())\n",
    "    plt.show()\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.pie(w.values(), labels=w.keys())\n",
    "#plt.legend(title=\"Sad:50% Fearful:37.5% Angry:12.5%\")\n",
    "    plt.show()\n",
    "    plt.suptitle(\"Twitter Sentiment Analysis\")\n",
    "    canvas = FigureCanvasTkAgg(figure, win)\n",
    "    \n",
    "#@@@@@@@@@@@@@@@@@@@@---------(Function For Facebook)----------@@@@@@@@@@@@@@@@@@#\n",
    "def fbInput():\n",
    "    fbInp = entry.get()\n",
    "    browser = webdriver.Firefox(executable_path=r'C:\\Users\\Israel\\anaconda3\\geckodriver')\n",
    "    browser.get(fbInp)\n",
    "#scroll to the end of the page\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(20)\n",
    "    comment = browser.find_elements_by_xpath('//div[@class=\"kvgmc6g5 cxmmr5t8 oygrvhab hcukyx3x c1et5uql\"]')\n",
    "    xcomment = []\n",
    "    x=0\n",
    "    for v in range(len(comment)):\n",
    "        xcomment.append(comment[v].text)\n",
    "        x+=1\n",
    "        #print((colored('COMMENT-', 'red', attrs=['bold'])) + str(x)+\" \"+\"is:\"+comment[v].text)\n",
    "    string = ' '.join([str(item) for item in xcomment])\n",
    "    lower_case = string.lower() \n",
    "    result = re.sub(r\"\\d+\", \"\", lower_case)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', result)\n",
    "#Tokenization\n",
    "    tokenized_words = cleaned_text.split()\n",
    "#Removing stopwords\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    final_words =[]\n",
    "    for word in tokenized_words:\n",
    "        if word not in stopwords:\n",
    "            final_words.append(word)\n",
    "        \n",
    "\n",
    "#To clear the lines type\n",
    "    emotion_list = []\n",
    "\n",
    "    with open('emotions.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            clear_line = line.replace(\"\\n\", '').replace(\",\", '').replace(\"'\", '').strip()\n",
    "            words, emotion = clear_line.split(':')\n",
    "            #print(\"Word:\"+words+\"     \"+\"Emotion:\" + emotion)\n",
    "            if words in final_words:\n",
    "                emotion_list.append(emotion)\n",
    "#To count the emotions\n",
    "    w = Counter(emotion_list)\n",
    "    #print(w)\n",
    "    figure = Figure(figsize=(3, 3), dpi=100)\n",
    "\n",
    "#PLOTTING THE GRAPHS\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.bar(w.keys(), w.values())\n",
    "    plt.show()\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.pie(w.values(), labels=w.keys())\n",
    "#plt.legend(title=\"Sad:50% Fearful:37.5% Angry:12.5%\")\n",
    "    plt.show()\n",
    "    plt.suptitle(\"Facebook Sentiment Analysis\")\n",
    "    canvas = FigureCanvasTkAgg(figure, win)\n",
    "    \n",
    "#@@@@@@@@@@@@@@@@@@@@---------(Function For NairaLand)----------@@@@@@@@@@@@@@@@@@#\n",
    "def NlInput():\n",
    "    NlInp = entry.get()\n",
    "    browser = webdriver.Firefox(executable_path=r'C:\\Users\\Israel\\anaconda3\\geckodriver')\n",
    "    browser.get(NlInp)\n",
    "#scroll to the end of the page\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(10)\n",
    "    comment = browser.find_elements_by_xpath('//div[@class=\"narrow\"]')\n",
    "    xcomment = []\n",
    "    x=0\n",
    "    for v in range(len(comment)):\n",
    "        xcomment.append(comment[v].text)\n",
    "        x+=1\n",
    "        #print((colored('COMMENT-', 'red', attrs=['bold'])) + str(x)+\" \"+\"is:\"+comment[v].text)\n",
    "    string = ' '.join([str(item) for item in xcomment])\n",
    "    lower_case = string.lower() \n",
    "    result = re.sub(r\"\\d+\", \"\", lower_case)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', result)\n",
    "#Tokenization\n",
    "    tokenized_words = cleaned_text.split()\n",
    "#Removing stopwords\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    final_words =[]\n",
    "    for word in tokenized_words:\n",
    "        if word not in stopwords:\n",
    "            final_words.append(word)\n",
    "        \n",
    "\n",
    "#To clear the lines type\n",
    "    emotion_list = []\n",
    "\n",
    "    with open('emotions.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            clear_line = line.replace(\"\\n\", '').replace(\",\", '').replace(\"'\", '').strip()\n",
    "            words, emotion = clear_line.split(':')\n",
    "            #print(\"Word:\"+words+\"     \"+\"Emotion:\" + emotion)\n",
    "            if words in final_words:\n",
    "                emotion_list.append(emotion)\n",
    "#To count the emotions\n",
    "    w = Counter(emotion_list)\n",
    "    #print(w)\n",
    "    figure = Figure(figsize=(3, 3), dpi=100)\n",
    "\n",
    "#PLOTTING THE GRAPHS\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.bar(w.keys(), w.values())\n",
    "    plt.show()\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.pie(w.values(), labels=w.keys())\n",
    "#plt.legend(title=\"Sad:50% Fearful:37.5% Angry:12.5%\")\n",
    "    plt.show()\n",
    "    plt.suptitle(\"Facebook Sentiment Analysis\")\n",
    "    canvas = FigureCanvasTkAgg(figure, win)\n",
    "  \n",
    "\n",
    "    \n",
    "#Header text Creation\n",
    "text = Label(text = \"Online Sentiment Analyzer\", fg=\"blue\", width=20, height=10)\n",
    "myFont = tkFont.Font(family=\"Times New Roman\", size=25, weight=\"bold\", slant=\"italic\")\n",
    "text.configure(font = myFont)\n",
    "text.pack()\n",
    "#Instruction text\n",
    "text2 = Label(text = \"Paste your page link below:\", fg=\"black\", width=20, height=5)\n",
    "myFont2 = tkFont.Font(family=\"Times New Roman\", size=15, weight=\"bold\")\n",
    "text2.configure(font = myFont2)\n",
    "text2.pack()\n",
    "# TextBox Creation\n",
    "entry = Entry(win, fg = \"green\", bg = \"white\", width=80)\n",
    "entry.pack()\n",
    "# Twitter Button Creation\n",
    "twitter_button = Button(win, text=\"Run Twitter\", width=15, height=1, bg=\"#1DA1F2\", fg=\"white\", command = twitterInput)\n",
    "twitter_button.pack()\n",
    "# Facebook Button Creation\n",
    "facebook_button = Button(win, text=\"Run Facebook\", width=15, height=1, bg=\"#4267B2\", fg=\"white\", command = fbInput)\n",
    "facebook_button.pack()\n",
    "# NairaLand Button Creation\n",
    "NairaLand_button = Button(win, text=\"Run NairaLand\", width=15, height=1, bg=\"green\", fg=\"white\", command = NlInput)\n",
    "NairaLand_button.pack()\n",
    "# Define a function to close the window\n",
    "def close():\n",
    "   #win.destroy()\n",
    "   win.quit()\n",
    "\n",
    "# Create a Button to call close()\n",
    "quit_button = Button(win, text=\"Quit\", width=15, height=1, bg=\"red\", fg=\"white\", command = close)\n",
    "quit_button.pack()\n",
    "\n",
    "#Instructions\n",
    "text3 = Label(text = \"Note:Make sure you are automatically logged into your accounts on your google chrome.\", fg=\"red\", width=70, height=5)\n",
    "myFont3 = tkFont.Font(family=\"Arial\", size=5)\n",
    "text3.configure(font = myFont2)\n",
    "text3.pack()\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ca4fe-17a8-48ef-9c5b-c0e4fa33b0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
